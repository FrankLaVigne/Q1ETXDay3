{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d430572a-0511-47b0-91c5-0b389f58d3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f04faf-57b3-480d-b225-315328cb182f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import snapshot_download\n",
    "snapshot_download(\"ibm-granite/granite-3.2-8b-instruct\", local_dir=\"./models/granite-3-2-8b-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f94740f-c2b1-4e8a-885d-0b17fabce5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading ibm-granite/granite-3.2-8b-instruct...\n",
      "This is approximately 16 GB. Time will vary based on network speed.\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24c9fc9e762450298f87f230bb32717",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 15 files:   0%|          | 0/15 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "886bf7c854f4432cb0307d00fbd6215e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44d4fc0674a948718021c59d5fd15537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbd94796ae30470b938bfabdfe35ca36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/87.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6451821d834b4bb1b591a5daa0223f7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "325e50ee1a5e46ddb2d9fce21c9639e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       ".gitattributes: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d67040cb92ee47c6ad29cf712c92b3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/137 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49f6c10139bb43c5b45b2028d7cc18ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.41G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9081f32019194926bcb181eef7931d32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.97G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a879f5c026514ce78b7d9a0cdf6950f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/789 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db805870602f4835b48f019d52cbf4a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c262f191db57464eb1cee9d72cd7844f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/701 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636db668a70e43a29a41c2d2505fb4af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c0e671001c4c2dbc7f1ae565f1927e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b09c41089ee485899313565dd081a34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90878631c4274a20b4dd52c940446ee2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Download complete: 1m 28s\n",
      "Saved to: ./models/granite-3-2-8b-instruct\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from huggingface_hub import snapshot_download\n",
    "\n",
    "model_id = \"ibm-granite/granite-3.2-8b-instruct\"\n",
    "local_dir = \"./models/granite-3-2-8b-instruct\"\n",
    "\n",
    "print(f\"Downloading {model_id}...\")\n",
    "print(\"This is approximately 16 GB. Time will vary based on network speed.\\n\")\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "snapshot_download(\n",
    "    repo_id=model_id,\n",
    "    local_dir=local_dir,\n",
    "    ignore_patterns=[\"*.gguf\", \"*.bin\"],  # Skip quantized formats we don't need\n",
    ")\n",
    "\n",
    "elapsed = time.time() - start\n",
    "minutes = int(elapsed // 60)\n",
    "seconds = int(elapsed % 60)\n",
    "\n",
    "print(f\"\\nDownload complete: {minutes}m {seconds}s\")\n",
    "print(f\"Saved to: {local_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a05082-33c3-4c16-b5e8-efb4d876eb39",
   "metadata": {},
   "source": [
    "## 2.2 Install training_hub\n",
    "\n",
    "Training Hub is the companion library to SDG Hub, also from the Red Hat AI Innovation Team. Where SDG Hub generates data, Training Hub consumes it. The library provides a single, consistent Python interface across multiple training algorithms: SFT, OSFT, LoRA, and others. You call a function, pass it a model path, a data path, and your hyperparameters. The library handles backend selection, distributed setup, and checkpoint management."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "977a30b0-cb36-4271-af8d-dd392f6a866f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "docling 2.58.0 requires huggingface_hub<1,>=0.23, but you have huggingface-hub 1.4.1 which is incompatible.\n",
      "docling-ibm-models 3.11.0 requires transformers<5.0.0,>=4.42.0, but you have transformers 5.2.0 which is incompatible.\n",
      "appengine-python-standard 1.1.10 requires urllib3<2,>=1.26.2, but you have urllib3 2.6.3 which is incompatible.\n",
      "codeflare-sdk 0.33.1 requires rich<14.0,>=12.5, but you have rich 14.3.2 which is incompatible.\n",
      "feast 0.58.0 requires dill~=0.3.0, but you have dill 0.4.0 which is incompatible.\n",
      "jupyter-resource-usage 1.1.1 requires psutil~=5.6, but you have psutil 7.2.2 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install training-hub -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69f8d0d2-362e-4693-8e6e-212edf69e46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install flash-attn --no-build-isolation -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "accde7fd-0fd7-4a6b-8c21-d182e90647fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install training-hub[cuda] -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bae08466-4b04-4205-ae83-d44a33f9dd61",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install training-hub[cuda] --no-deps -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8711612d-5b73-46b9-96a5-e44e95b32988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 19 04:15:39 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L40S                    On  |   00000000:30:00.0 Off |                    0 |\n",
      "| N/A   43C    P0            101W /  350W |    6663MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1123      C   /opt/app-root/bin/python3              1818MiB |\n",
      "|    0   N/A  N/A            2759      C   /opt/app-root/bin/python3              1756MiB |\n",
      "|    0   N/A  N/A            3423      C   /opt/app-root/bin/python3               768MiB |\n",
      "|    0   N/A  N/A            4192      C   /opt/app-root/bin/python3              2296MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "! nvidia-smi "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20f161ac-1232-41fc-b020-71aa63ce2661",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.12.9\n",
      "2.7.1+cu128\n"
     ]
    }
   ],
   "source": [
    "! python --version && python -c \"import torch; print(torch.__version__)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffa84335-97d1-43b4-94cf-ac8974f5d14f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m  ERROR: HTTP error 404 while getting https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.8.3+cu128torch2.7-cp312-cp312-linux_x86_64.whl\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not install requirement flash-attn==2.8.3+cu128torch2.7 from https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.8.3+cu128torch2.7-cp312-cp312-linux_x86_64.whl because of HTTP error 404 Client Error: Not Found for url: https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.8.3+cu128torch2.7-cp312-cp312-linux_x86_64.whl for URL https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.8.3+cu128torch2.7-cp312-cp312-linux_x86_64.whl\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.8.3+cu128torch2.7-cp312-cp312-linux_x86_64.whl -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f60caf9-0adf-4e7d-94a4-73cb46c11c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m  ERROR: HTTP error 404 while getting https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.8.3+cu128torch2.7-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: Could not install requirement flash-attn==2.8.3+cu128torch2.7 from https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.8.3+cu128torch2.7-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl because of HTTP error 404 Client Error: Not Found for url: https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.8.3+cu128torch2.7-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl for URL https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.8.3+cu128torch2.7-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "! pip install https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.0.0/flash_attn-2.8.3+cu128torch2.7-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl -q\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c5bb3647-553a-423a-baf9-047040242901",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting flash-attn==2.8.3+cu128torch2.7\n",
      "  Downloading https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.5.4/flash_attn-2.8.3+cu128torch2.7-cp312-cp312-linux_x86_64.whl (253.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.6/253.6 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m  \u001b[33m0:00:04\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/app-root/lib64/python3.12/site-packages (from flash-attn==2.8.3+cu128torch2.7) (2.7.1+cu128)\n",
      "Requirement already satisfied: einops in /opt/app-root/lib64/python3.12/site-packages (from flash-attn==2.8.3+cu128torch2.7) (0.8.2)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (9.7.1.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (1.13.0.11)\n",
      "Requirement already satisfied: triton==3.3.1 in /opt/app-root/lib64/python3.12/site-packages (from torch->flash-attn==2.8.3+cu128torch2.7) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/app-root/lib64/python3.12/site-packages (from sympy>=1.13.3->torch->flash-attn==2.8.3+cu128torch2.7) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.12/site-packages (from jinja2->torch->flash-attn==2.8.3+cu128torch2.7) (3.0.3)\n",
      "Installing collected packages: flash-attn\n",
      "  Attempting uninstall: flash-attn\n",
      "    Found existing installation: flash_attn 2.8.3\n",
      "    Uninstalling flash_attn-2.8.3:\n",
      "      Successfully uninstalled flash_attn-2.8.3\n",
      "Successfully installed flash-attn-2.8.3+cu128torch2.7\n"
     ]
    }
   ],
   "source": [
    "! pip install https://github.com/mjun0812/flash-attention-prebuild-wheels/releases/download/v0.5.4/flash_attn-2.8.3+cu128torch2.7-cp312-cp312-linux_x86_64.whl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2a08950-98d7-42fa-ad87-028067e50676",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: training-hub[cuda] in /opt/app-root/lib64/python3.12/site-packages (0.5.0)\n",
      "Requirement already satisfied: setuptools>=80.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (80.9.0)\n",
      "Requirement already satisfied: packaging>=24.2 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (25.0)\n",
      "Requirement already satisfied: wheel>=0.43 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (0.45.1)\n",
      "Requirement already satisfied: instructlab-training>=0.13.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (0.14.1)\n",
      "Requirement already satisfied: rhai-innovation-mini-trainer>=0.5.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (0.6.0)\n",
      "Requirement already satisfied: torch>=2.6.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (2.7.1+cu128)\n",
      "Requirement already satisfied: numba>=0.62.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (0.64.0)\n",
      "Requirement already satisfied: transformers>=4.57.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (5.2.0)\n",
      "Requirement already satisfied: datasets>=4.0.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (4.5.0)\n",
      "Requirement already satisfied: numpy>=1.26.4 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (2.3.5)\n",
      "Requirement already satisfied: rich>=14.1.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (14.3.2)\n",
      "Requirement already satisfied: peft>=0.15 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (0.18.1)\n",
      "Requirement already satisfied: pydantic>=2.7.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (2.12.5)\n",
      "Requirement already satisfied: aiofiles>=23.2.1 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (25.1.0)\n",
      "Requirement already satisfied: accelerate>=0.34.2 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (1.12.0)\n",
      "Requirement already satisfied: sympy>=1.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (1.14.0)\n",
      "Requirement already satisfied: networkx>=3.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (3.6.1)\n",
      "Requirement already satisfied: jinja2>=3.1.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=2025.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (2025.10.0)\n",
      "Requirement already satisfied: pandas>=2.2 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (2.3.3)\n",
      "Requirement already satisfied: multiprocess>=0.70.16 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (0.70.18)\n",
      "Requirement already satisfied: aiohttp>=3.12 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (3.13.2)\n",
      "Requirement already satisfied: pyparsing>=3.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (3.2.5)\n",
      "Requirement already satisfied: regex>=2025.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (2026.1.15)\n",
      "Requirement already satisfied: llvmlite>=0.42 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (0.46.0)\n",
      "Requirement already satisfied: filelock>=3.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (3.20.0)\n",
      "Requirement already satisfied: psutil>=6.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (7.2.2)\n",
      "Requirement already satisfied: urllib3>=2.4 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (2.6.3)\n",
      "Requirement already satisfied: frozenlist>=1.7 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (1.8.0)\n",
      "Requirement already satisfied: xxhash>=3.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (3.6.0)\n",
      "Requirement already satisfied: requests>=2.32.5 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (2.32.5)\n",
      "Requirement already satisfied: attr>=0.3.2 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (0.3.2)\n",
      "Requirement already satisfied: mpmath>=1.3.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (1.3.0)\n",
      "Requirement already satisfied: pytest>=8.0 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (9.0.2)\n",
      "Requirement already satisfied: flash-attn>=2.8 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (2.8.3+cu128torch2.7)\n",
      "Requirement already satisfied: einops>=0.8 in /opt/app-root/lib64/python3.12/site-packages (from training-hub[cuda]) (0.8.2)\n",
      "Collecting kernels>=0.9.0 (from training-hub[cuda])\n",
      "  Downloading kernels-0.12.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting bitsandbytes>=0.47.0 (from training-hub[cuda])\n",
      "  Downloading bitsandbytes-0.49.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Collecting liger-kernel>=0.5.10 (from training-hub[cuda])\n",
      "  Downloading liger_kernel-0.7.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting mamba-ssm>=2.2.5 (from mamba-ssm[causal-conv1d]>=2.2.5; extra == \"cuda\"->training-hub[cuda])\n",
      "  Downloading mamba_ssm-2.3.0.tar.gz (121 kB)\n",
      "  Installing build dependencies ... \u001b[?25l^C\n",
      "\u001b[?25canceled\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# Step 2: training-hub with CUDA support\n",
    "! pip install training-hub[cuda] \n",
    "\n",
    "# TODO: add the -q back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "540b0a23-8eb3-4ece-9a4b-2ce172ac8d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mamba-ssm\n",
      "  Downloading mamba_ssm-2.3.0.tar.gz (121 kB)\n",
      "  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: torch in /opt/app-root/lib64/python3.12/site-packages (from mamba-ssm) (2.7.1+cu128)\n",
      "Requirement already satisfied: triton in /opt/app-root/lib64/python3.12/site-packages (from mamba-ssm) (3.3.1)\n",
      "Requirement already satisfied: ninja in /opt/app-root/lib64/python3.12/site-packages (from mamba-ssm) (1.13.0)\n",
      "Requirement already satisfied: einops in /opt/app-root/lib64/python3.12/site-packages (from mamba-ssm) (0.8.2)\n",
      "Requirement already satisfied: transformers in /opt/app-root/lib64/python3.12/site-packages (from mamba-ssm) (5.2.0)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib64/python3.12/site-packages (from mamba-ssm) (25.0)\n",
      "Requirement already satisfied: setuptools>=61.0.0 in /opt/app-root/lib64/python3.12/site-packages (from mamba-ssm) (80.9.0)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (2025.10.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (9.7.1.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /opt/app-root/lib64/python3.12/site-packages (from torch->mamba-ssm) (1.13.0.11)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/app-root/lib64/python3.12/site-packages (from sympy>=1.13.3->torch->mamba-ssm) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.12/site-packages (from jinja2->torch->mamba-ssm) (3.0.3)\n",
      "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /opt/app-root/lib64/python3.12/site-packages (from transformers->mamba-ssm) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib64/python3.12/site-packages (from transformers->mamba-ssm) (2.3.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.12/site-packages (from transformers->mamba-ssm) (6.0.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib64/python3.12/site-packages (from transformers->mamba-ssm) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/app-root/lib64/python3.12/site-packages (from transformers->mamba-ssm) (0.22.2)\n",
      "Requirement already satisfied: typer-slim in /opt/app-root/lib64/python3.12/site-packages (from transformers->mamba-ssm) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/app-root/lib64/python3.12/site-packages (from transformers->mamba-ssm) (0.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/app-root/lib64/python3.12/site-packages (from transformers->mamba-ssm) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /opt/app-root/lib64/python3.12/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers->mamba-ssm) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/app-root/lib64/python3.12/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers->mamba-ssm) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /opt/app-root/lib64/python3.12/site-packages (from huggingface-hub<2.0,>=1.3.0->transformers->mamba-ssm) (1.5.4)\n",
      "Requirement already satisfied: anyio in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers->mamba-ssm) (4.12.0)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers->mamba-ssm) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers->mamba-ssm) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers->mamba-ssm) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/app-root/lib64/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers->mamba-ssm) (0.16.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/app-root/lib64/python3.12/site-packages (from typer-slim->transformers->mamba-ssm) (8.1.8)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /opt/app-root/lib64/python3.12/site-packages (from typer-slim->transformers->mamba-ssm) (0.0.4)\n",
      "Building wheels for collected packages: mamba-ssm\n",
      "  Building wheel for mamba-ssm (pyproject.toml) ... \u001b[?25l/^C\n",
      "\u001b[?25canceled\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install mamba-ssm --no-build-isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef8ffa08-1794-4537-87b1-963738d433ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kernels in /opt/app-root/lib64/python3.12/site-packages (0.12.1)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.49.2-py3-none-manylinux_2_24_x86_64.whl.metadata (10 kB)\n",
      "Requirement already satisfied: liger-kernel in /opt/app-root/lib64/python3.12/site-packages (0.7.0)\n",
      "Requirement already satisfied: huggingface_hub<2.0,>=0.26.0 in /opt/app-root/lib64/python3.12/site-packages (from kernels) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/app-root/lib64/python3.12/site-packages (from kernels) (25.0)\n",
      "Requirement already satisfied: pyyaml>=6 in /opt/app-root/lib64/python3.12/site-packages (from kernels) (6.0.3)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.12/site-packages (from huggingface_hub<2.0,>=0.26.0->kernels) (3.20.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/app-root/lib64/python3.12/site-packages (from huggingface_hub<2.0,>=0.26.0->kernels) (2025.10.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /opt/app-root/lib64/python3.12/site-packages (from huggingface_hub<2.0,>=0.26.0->kernels) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/app-root/lib64/python3.12/site-packages (from huggingface_hub<2.0,>=0.26.0->kernels) (0.28.1)\n",
      "Requirement already satisfied: shellingham in /opt/app-root/lib64/python3.12/site-packages (from huggingface_hub<2.0,>=0.26.0->kernels) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/app-root/lib64/python3.12/site-packages (from huggingface_hub<2.0,>=0.26.0->kernels) (4.67.1)\n",
      "Requirement already satisfied: typer-slim in /opt/app-root/lib64/python3.12/site-packages (from huggingface_hub<2.0,>=0.26.0->kernels) (0.21.2)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /opt/app-root/lib64/python3.12/site-packages (from huggingface_hub<2.0,>=0.26.0->kernels) (4.15.0)\n",
      "Requirement already satisfied: anyio in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub<2.0,>=0.26.0->kernels) (4.12.0)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub<2.0,>=0.26.0->kernels) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub<2.0,>=0.26.0->kernels) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/app-root/lib64/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub<2.0,>=0.26.0->kernels) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/app-root/lib64/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub<2.0,>=0.26.0->kernels) (0.16.0)\n",
      "Requirement already satisfied: torch<3,>=2.3 in /opt/app-root/lib64/python3.12/site-packages (from bitsandbytes) (2.7.1+cu128)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/app-root/lib64/python3.12/site-packages (from bitsandbytes) (2.3.5)\n",
      "Requirement already satisfied: setuptools in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (9.7.1.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (1.13.0.11)\n",
      "Requirement already satisfied: triton==3.3.1 in /opt/app-root/lib64/python3.12/site-packages (from torch<3,>=2.3->bitsandbytes) (3.3.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/app-root/lib64/python3.12/site-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.12/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes) (3.0.3)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/app-root/lib64/python3.12/site-packages (from typer-slim->huggingface_hub<2.0,>=0.26.0->kernels) (8.1.8)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /opt/app-root/lib64/python3.12/site-packages (from typer-slim->huggingface_hub<2.0,>=0.26.0->kernels) (0.0.4)\n",
      "Downloading bitsandbytes-0.49.2-py3-none-manylinux_2_24_x86_64.whl (60.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.7/60.7 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: bitsandbytes\n",
      "Successfully installed bitsandbytes-0.49.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kernels bitsandbytes liger-kernel "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050cebad-b775-4ca5-b193-49817b37de7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3c1f79-1197-4fcd-91e1-8f7781e2da43",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3410e35e-c569-4b88-b152-141be61a3bb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sft', 'osft', 'lora_sft']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from training_hub import AlgorithmRegistry\n",
    "AlgorithmRegistry.list_algorithms()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fc4f46-e6d4-4bef-bc44-36187c72c723",
   "metadata": {},
   "source": [
    "## 2.3 Preparing Training Data (CSV to JSONL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f8292bd-5d7b-4f94-94e8-e6a0eebfc6ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated QA pairs: 6\n",
      "Columns: ['question', 'response', 'faithfulness_judgment']\n",
      "\n",
      "First example:\n",
      "  Q: What are the base ability percentages for Open Locks, Remove Traps, Pick Pockets, and Climb Walls for a Level 1 Thief?...\n",
      "  A: Based on the provided document, the base ability percentages for a Level 1 Thief are as follows:\n",
      "\n",
      "- **Open Locks:** 25%\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Load the sdg_hub output\n",
    "csv_path = \"../01SDG/synthetic_qa_pairs.csv\"\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"Generated QA pairs: {len(df)}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "print(f\"\\nFirst example:\")\n",
    "print(f\"  Q: {df.iloc[0]['question'][:120]}...\")\n",
    "print(f\"  A: {df.iloc[0]['response'][:120]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efd4c795-76e4-4902-a467-8a5f7b9f2fef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faithfulness_judgment\n",
      "YES    6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"faithfulness_judgment\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3cf290cc-2a6d-45fd-8af6-fb3de00c869e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 6 training examples to training_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "SYSTEM_PROMPT = (\n",
    "    \"You are a knowledgeable assistant for the Basic Fantasy Role-Playing Game. \"\n",
    "    \"Answer questions accurately based on the official Basic Fantasy RPG rules. \"\n",
    "    \"If a rule is edition-specific, cite the relevant section.\"\n",
    ")\n",
    "\n",
    "output_path = \"training_data.jsonl\"\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for _, row in df.iterrows():\n",
    "        record = {\n",
    "            \"messages\": [\n",
    "                {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "                {\"role\": \"user\", \"content\": row[\"question\"].strip()},\n",
    "                {\"role\": \"assistant\", \"content\": row[\"response\"].strip()},\n",
    "            ]\n",
    "        }\n",
    "        f.write(json.dumps(record, ensure_ascii=False) + \"\\n\")\n",
    "\n",
    "print(f\"Wrote {len(df)} training examples to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "db013e77-eb5d-4396-a0a9-f5dc2bf02288",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lines in JSONL: 6\n",
      "{\n",
      "  \"messages\": [\n",
      "    {\n",
      "      \"role\": \"system\",\n",
      "      \"content\": \"You are a knowledgeable assistant for the Basic Fantasy Role-Playing Game. Answer questions accurately based on the official Basic Fantasy RPG rules. If a rule is edition-specific, cite the relevant section.\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"user\",\n",
      "      \"content\": \"What are the base ability percentages for Open Locks, Remove Traps, Pick Pockets, and Climb Walls for a Level 1 Thief?\"\n",
      "    },\n",
      "    {\n",
      "      \"role\": \"assistant\",\n",
      "      \"content\": \"Based on the provided document, the base ability percentages for a Level 1 Thief are as follow\n"
     ]
    }
   ],
   "source": [
    "with open(output_path, \"r\") as f:\n",
    "    lines = f.readlines()\n",
    "\n",
    "print(f\"Lines in JSONL: {len(lines)}\")\n",
    "first = json.loads(lines[0])\n",
    "print(json.dumps(first, indent=2)[:600])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bbd7adc-0c74-485d-a7f2-ce4a1681bac4",
   "metadata": {},
   "source": [
    "## Next section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20041da4-d4cc-4947-840c-d8a4edcae375",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting unsloth\n",
      "  Downloading unsloth-2026.2.1-py3-none-any.whl.metadata (69 kB)\n",
      "Collecting unsloth_zoo>=2026.2.1 (from unsloth)\n",
      "  Downloading unsloth_zoo-2026.2.1-py3-none-any.whl.metadata (32 kB)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /opt/app-root/lib64/python3.12/site-packages (from unsloth) (0.45.1)\n",
      "Requirement already satisfied: packaging in /opt/app-root/lib64/python3.12/site-packages (from unsloth) (25.0)\n",
      "Requirement already satisfied: torch>=2.4.0 in /opt/app-root/lib64/python3.12/site-packages (from unsloth) (2.7.1+cu128)\n",
      "Requirement already satisfied: torchvision in /opt/app-root/lib64/python3.12/site-packages (from unsloth) (0.22.1+cu128)\n",
      "Requirement already satisfied: numpy in /opt/app-root/lib64/python3.12/site-packages (from unsloth) (2.3.5)\n",
      "Requirement already satisfied: tqdm in /opt/app-root/lib64/python3.12/site-packages (from unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/app-root/lib64/python3.12/site-packages (from unsloth) (7.2.2)\n",
      "Collecting tyro (from unsloth)\n",
      "  Downloading tyro-1.0.6-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: protobuf in /opt/app-root/lib64/python3.12/site-packages (from unsloth) (6.33.2)\n",
      "Collecting xformers>=0.0.27.post2 (from unsloth)\n",
      "  Downloading xformers-0.0.34-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: bitsandbytes!=0.46.0,!=0.48.0,>=0.45.5 in /opt/app-root/lib64/python3.12/site-packages (from unsloth) (0.49.2)\n",
      "Requirement already satisfied: triton>=3.0.0 in /opt/app-root/lib64/python3.12/site-packages (from unsloth) (3.3.1)\n",
      "Collecting sentencepiece>=0.2.0 (from unsloth)\n",
      "  Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (10 kB)\n",
      "Collecting datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 (from unsloth)\n",
      "  Downloading datasets-4.3.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /opt/app-root/lib64/python3.12/site-packages (from unsloth) (1.12.0)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.18.0 in /opt/app-root/lib64/python3.12/site-packages (from unsloth) (0.18.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in /opt/app-root/lib64/python3.12/site-packages (from unsloth) (1.4.1)\n",
      "Collecting hf_transfer (from unsloth)\n",
      "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting diffusers (from unsloth)\n",
      "  Downloading diffusers-0.36.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3 (from unsloth)\n",
      "  Downloading transformers-4.57.6-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting trl!=0.19.0,<=0.24.0,>=0.18.2 (from unsloth)\n",
      "  Downloading trl-0.24.0-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: filelock in /opt/app-root/lib64/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/app-root/lib64/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (21.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/app-root/lib64/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/app-root/lib64/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/app-root/lib64/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/app-root/lib64/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /opt/app-root/lib64/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.6.0)\n",
      "Collecting multiprocess<0.70.17 (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2025.9.0,>=2023.1.0 (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth)\n",
      "  Downloading fsspec-2025.9.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/app-root/lib64/python3.12/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/app-root/lib64/python3.12/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.13.2)\n",
      "Requirement already satisfied: anyio in /opt/app-root/lib64/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (4.12.0)\n",
      "Requirement already satisfied: certifi in /opt/app-root/lib64/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.11.12)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/app-root/lib64/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/app-root/lib64/python3.12/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/app-root/lib64/python3.12/site-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /opt/app-root/lib64/python3.12/site-packages (from huggingface_hub>=0.34.0->unsloth) (1.2.0)\n",
      "Requirement already satisfied: shellingham in /opt/app-root/lib64/python3.12/site-packages (from huggingface_hub>=0.34.0->unsloth) (1.5.4)\n",
      "Requirement already satisfied: typer-slim in /opt/app-root/lib64/python3.12/site-packages (from huggingface_hub>=0.34.0->unsloth) (0.21.2)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in /opt/app-root/lib64/python3.12/site-packages (from huggingface_hub>=0.34.0->unsloth) (4.15.0)\n",
      "Collecting huggingface_hub>=0.34.0 (from unsloth)\n",
      "  Downloading huggingface_hub-0.36.2-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/app-root/lib64/python3.12/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3->unsloth) (2026.1.15)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/app-root/lib64/python3.12/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3->unsloth) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/app-root/lib64/python3.12/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,!=4.57.4,!=4.57.5,<=4.57.6,>=4.51.3->unsloth) (0.7.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/app-root/lib64/python3.12/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.22.0)\n",
      "Requirement already satisfied: setuptools in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.61 in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.57 in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.57 in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.8.57)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.7.1.26 in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (9.7.1.26)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.3.14 in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.8.3.14)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.41 in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (11.3.3.41)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.55 in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (10.3.9.55)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.2.55 in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (11.7.2.55)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.7.53 in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.5.7.53)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.3 in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (0.6.3)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.26.2 in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (2.26.2)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.55 in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.8.55)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.61 in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (12.8.61)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.0.11 in /opt/app-root/lib64/python3.12/site-packages (from torch>=2.4.0->unsloth) (1.13.0.11)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/app-root/lib64/python3.12/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/app-root/lib64/python3.12/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.6.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/app-root/lib64/python3.12/site-packages (from sympy>=1.13.3->torch>=2.4.0->unsloth) (1.3.0)\n",
      "Collecting torchao>=0.13.0 (from unsloth_zoo>=2026.2.1->unsloth)\n",
      "  Downloading torchao-0.16.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (20 kB)\n",
      "Collecting cut_cross_entropy (from unsloth_zoo>=2026.2.1->unsloth)\n",
      "  Downloading cut_cross_entropy-25.1.1-py3-none-any.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: pillow in /opt/app-root/lib64/python3.12/site-packages (from unsloth_zoo>=2026.2.1->unsloth) (11.3.0)\n",
      "Collecting msgspec (from unsloth_zoo>=2026.2.1->unsloth)\n",
      "  Downloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.5 kB)\n",
      "Collecting torch>=2.4.0 (from unsloth)\n",
      "  Downloading torch-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (31 kB)\n",
      "Collecting cuda-bindings==12.9.4 (from torch>=2.4.0->unsloth)\n",
      "  Downloading cuda_bindings-12.9.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (2.6 kB)\n",
      "Collecting nvidia-cuda-nvrtc-cu12==12.8.93 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-runtime-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cuda-cupti-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cudnn-cu12==9.10.2.21 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12==9.7.1.26->torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufft-cu12==11.3.3.83 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-curand-cu12==10.3.9.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cusolver-cu12==11.7.3.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparse-cu12 (from nvidia-cusolver-cu12==11.7.2.55->torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-cusparselt-cu12==0.7.1 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl.metadata (7.0 kB)\n",
      "Collecting nvidia-nccl-cu12==2.27.5 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.0 kB)\n",
      "Collecting nvidia-nvshmem-cu12==3.4.5 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (2.1 kB)\n",
      "Collecting nvidia-nvtx-cu12==12.8.90 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvjitlink-cu12 (from nvidia-cufft-cu12==11.3.3.41->torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting nvidia-cufile-cu12==1.13.1.3 (from torch>=2.4.0->unsloth)\n",
      "  Downloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton>=3.0.0 (from unsloth)\n",
      "  Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting cuda-pathfinder~=1.1 (from cuda-bindings==12.9.4->torch>=2.4.0->unsloth)\n",
      "  Downloading cuda_pathfinder-1.3.4-py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: importlib_metadata in /opt/app-root/lib64/python3.12/site-packages (from diffusers->unsloth) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/app-root/lib64/python3.12/site-packages (from importlib_metadata->diffusers->unsloth) (3.23.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/app-root/lib64/python3.12/site-packages (from jinja2->torch>=2.4.0->unsloth) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/app-root/lib64/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/app-root/lib64/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/app-root/lib64/python3.12/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/app-root/lib64/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth) (1.17.0)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision (from unsloth)\n",
      "  Downloading torchvision-0.25.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/app-root/lib64/python3.12/site-packages (from typer-slim->huggingface_hub>=0.34.0->unsloth) (8.1.8)\n",
      "Requirement already satisfied: annotated-doc>=0.0.2 in /opt/app-root/lib64/python3.12/site-packages (from typer-slim->huggingface_hub>=0.34.0->unsloth) (0.0.4)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /opt/app-root/lib64/python3.12/site-packages (from tyro->unsloth) (0.17.0)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /opt/app-root/lib64/python3.12/site-packages (from tyro->unsloth) (4.4.4)\n",
      "Downloading unsloth-2026.2.1-py3-none-any.whl (432 kB)\n",
      "Downloading datasets-4.3.0-py3-none-any.whl (506 kB)\n",
      "Downloading fsspec-2025.9.0-py3-none-any.whl (199 kB)\n",
      "Downloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "Downloading transformers-4.57.6-py3-none-any.whl (12.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m361.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading huggingface_hub-0.36.2-py3-none-any.whl (566 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m566.4/566.4 kB\u001b[0m \u001b[31m616.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading trl-0.24.0-py3-none-any.whl (423 kB)\n",
      "Downloading sentencepiece-0.2.1-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m516.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading unsloth_zoo-2026.2.1-py3-none-any.whl (376 kB)\n",
      "Downloading torchao-0.16.0-cp310-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m438.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading xformers-0.0.34-cp39-abi3-manylinux_2_28_x86_64.whl (110.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.8/110.8 MB\u001b[0m \u001b[31m272.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.10.0-cp312-cp312-manylinux_2_28_x86_64.whl (915.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m915.7/915.7 MB\u001b[0m \u001b[31m457.9 MB/s\u001b[0m  \u001b[33m0:00:02\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading cuda_bindings-12.9.4-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (12.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m467.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cublas_cu12-12.8.4.1-py3-none-manylinux_2_27_x86_64.whl (594.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.3/594.3 MB\u001b[0m \u001b[31m453.3 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (10.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m473.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (88.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.0/88.0 MB\u001b[0m \u001b[31m462.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (954 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m954.8/954.8 kB\u001b[0m \u001b[31m706.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu12-9.10.2.21-py3-none-manylinux_2_27_x86_64.whl (706.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m706.8/706.8 MB\u001b[0m \u001b[31m451.1 MB/s\u001b[0m  \u001b[33m0:00:01\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu12-11.3.3.83-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (193.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.1/193.1 MB\u001b[0m \u001b[31m454.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufile_cu12-1.13.1.3-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m716.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu12-10.3.9.90-py3-none-manylinux_2_27_x86_64.whl (63.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.6/63.6 MB\u001b[0m \u001b[31m469.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu12-11.7.3.90-py3-none-manylinux_2_27_x86_64.whl (267.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.5/267.5 MB\u001b[0m \u001b[31m485.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu12-12.5.8.93-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (288.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.2/288.2 MB\u001b[0m \u001b[31m479.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.7.1-py3-none-manylinux2014_x86_64.whl (287.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m287.2/287.2 MB\u001b[0m \u001b[31m462.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.27.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (322.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m322.3/322.3 MB\u001b[0m \u001b[31m467.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.8.93-py3-none-manylinux2010_x86_64.manylinux_2_12_x86_64.whl (39.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m414.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvshmem_cu12-3.4.5-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (139.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.1/139.1 MB\u001b[0m \u001b[31m476.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu12-12.8.90-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (89 kB)\n",
      "Downloading triton-3.6.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (188.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.3/188.3 MB\u001b[0m \u001b[31m489.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading cuda_pathfinder-1.3.4-py3-none-any.whl (30 kB)\n",
      "Downloading cut_cross_entropy-25.1.1-py3-none-any.whl (22 kB)\n",
      "Downloading diffusers-0.36.0-py3-none-any.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m473.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m184.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading msgspec-0.20.0-cp312-cp312-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (224 kB)\n",
      "Downloading torchvision-0.25.0-cp312-cp312-manylinux_2_28_x86_64.whl (8.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m372.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tyro-1.0.6-py3-none-any.whl (181 kB)\n",
      "Installing collected packages: torchao, nvidia-cusparselt-cu12, triton, sentencepiece, nvidia-nvtx-cu12, nvidia-nvshmem-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufile-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, multiprocess, msgspec, hf_transfer, fsspec, cuda-pathfinder, tyro, nvidia-cusparse-cu12, nvidia-cufft-cu12, nvidia-cudnn-cu12, huggingface_hub, cuda-bindings, nvidia-cusolver-cu12, diffusers, transformers, torch, datasets, xformers, torchvision, cut_cross_entropy, trl, unsloth_zoo, unsloth\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparselt-cu12━━\u001b[0m \u001b[32m 0/36\u001b[0m [torchao]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparselt-cu12 0.6.30m [torchao]\n",
      "\u001b[2K    Uninstalling nvidia-cusparselt-cu12-0.6.3:0m \u001b[32m 0/36\u001b[0m [torchao]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparselt-cu12-0.6.3━━━━━━━\u001b[0m \u001b[32m 1/36\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K  Attempting uninstall: triton━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/36\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Found existing installation: triton 3.3.1━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/36\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K    Uninstalling triton-3.3.1:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 1/36\u001b[0m [nvidia-cusparselt-cu12]\n",
      "\u001b[2K      Successfully uninstalled triton-3.3.1━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 2/36\u001b[0m [triton]arselt-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvtx-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/36\u001b[0m [sentencepiece]\n",
      "\u001b[2K    Found existing installation: nvidia-nvtx-cu12 12.8.55━━━━━\u001b[0m \u001b[32m 3/36\u001b[0m [sentencepiece]\n",
      "\u001b[2K    Uninstalling nvidia-nvtx-cu12-12.8.55:━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 3/36\u001b[0m [sentencepiece]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvtx-cu12-12.8.55━━━━━━━\u001b[0m \u001b[32m 3/36\u001b[0m [sentencepiece]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nvjitlink-cu12━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/36\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nvjitlink-cu12 12.8.61\u001b[0m \u001b[32m 5/36\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nvjitlink-cu12-12.8.61:━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 5/36\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.61━━\u001b[0m \u001b[32m 5/36\u001b[0m [nvidia-nvshmem-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-nccl-cu12━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/36\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-nccl-cu12 2.26.2━━━━━━\u001b[0m \u001b[32m 6/36\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-nccl-cu12-2.26.2:━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 6/36\u001b[0m [nvidia-nvjitlink-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-nccl-cu12-2.26.2━━━━━━━━━━━━\u001b[0m \u001b[32m 7/36\u001b[0m [nvidia-nccl-cu12]]\n",
      "\u001b[2K  Attempting uninstall: nvidia-curand-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/36\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-curand-cu12 10.3.9.55━\u001b[0m \u001b[32m 7/36\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-curand-cu12-10.3.9.55:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/36\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-curand-cu12-10.3.9.55━━━\u001b[0m \u001b[32m 7/36\u001b[0m [nvidia-nccl-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufile-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/36\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufile-cu12 1.13.0.11━\u001b[0m \u001b[32m 8/36\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufile-cu12-1.13.0.11:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/36\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufile-cu12-1.13.0.11━━━\u001b[0m \u001b[32m 8/36\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-runtime-cu12━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/36\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-runtime-cu12 12.8.57m \u001b[32m 8/36\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-runtime-cu12-12.8.57:━━━━━━━━━━━━\u001b[0m \u001b[32m 8/36\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-runtime-cu12-12.8.57[0m \u001b[32m 8/36\u001b[0m [nvidia-curand-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-nvrtc-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/36\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-nvrtc-cu12 12.8.61[0m \u001b[32m10/36\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-nvrtc-cu12-12.8.61:━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/36\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.8.61━\u001b[0m \u001b[32m10/36\u001b[0m [nvidia-cuda-runtime-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cuda-cupti-cu12━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/36\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cuda-cupti-cu12 12.8.57[0m \u001b[32m11/36\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cuda-cupti-cu12-12.8.57:━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/36\u001b[0m [nvidia-cuda-nvrtc-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cuda-cupti-cu12-12.8.57━━━━━\u001b[0m \u001b[32m12/36\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cublas-cu12━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/36\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cublas-cu12 12.8.3.14━\u001b[0m \u001b[32m12/36\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cublas-cu12-12.8.3.14:━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12/36\u001b[0m [nvidia-cuda-cupti-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cublas-cu12-12.8.3.14━━━━━━━\u001b[0m \u001b[32m13/36\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: multiprocess\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/36\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Found existing installation: multiprocess 0.70.18━━━━━━━━━\u001b[0m \u001b[32m13/36\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K    Uninstalling multiprocess-0.70.18:━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13/36\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K      Successfully uninstalled multiprocess-0.70.18━━━━━━━━━━━\u001b[0m \u001b[32m13/36\u001b[0m [nvidia-cublas-cu12]\n",
      "\u001b[2K  Attempting uninstall: fsspec1m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/36\u001b[0m [multiprocess]2]\n",
      "\u001b[2K    Found existing installation: fsspec 2025.10.0━━━━━━━━━━━━━\u001b[0m \u001b[32m14/36\u001b[0m [multiprocess]\n",
      "\u001b[2K    Uninstalling fsspec-2025.10.0:m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/36\u001b[0m [fsspec]s]\n",
      "\u001b[2K      Successfully uninstalled fsspec-2025.10.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17/36\u001b[0m [fsspec]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusparse-cu12[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/36\u001b[0m [tyro]\n",
      "\u001b[2K    Found existing installation: nvidia-cusparse-cu12 12.5.7.53[0m \u001b[32m19/36\u001b[0m [tyro]\n",
      "\u001b[2K    Uninstalling nvidia-cusparse-cu12-12.5.7.53:━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/36\u001b[0m [tyro]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusparse-cu12-12.5.7.53━━━━━\u001b[0m \u001b[32m20/36\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cufft-cu12[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/36\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cufft-cu12 11.3.3.41━━\u001b[0m \u001b[32m20/36\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cufft-cu12-11.3.3.41:━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20/36\u001b[0m [nvidia-cusparse-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cufft-cu12-11.3.3.41━━━━━━━━\u001b[0m \u001b[32m21/36\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cudnn-cu12\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/36\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Found existing installation: nvidia-cudnn-cu12 9.7.1.26━━━\u001b[0m \u001b[32m21/36\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K    Uninstalling nvidia-cudnn-cu12-9.7.1.26:0m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/36\u001b[0m [nvidia-cufft-cu12]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cudnn-cu12-9.7.1.26━━━━━━━━━\u001b[0m \u001b[32m22/36\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: huggingface_hub0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/36\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Found existing installation: huggingface_hub 1.4.1━━━━━━━━\u001b[0m \u001b[32m22/36\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K    Uninstalling huggingface_hub-1.4.1:[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22/36\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K      Successfully uninstalled huggingface_hub-1.4.1━━━━━━━━━━\u001b[0m \u001b[32m22/36\u001b[0m [nvidia-cudnn-cu12]\n",
      "\u001b[2K  Attempting uninstall: nvidia-cusolver-cu12\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m24/36\u001b[0m [cuda-bindings]b]\n",
      "\u001b[2K    Found existing installation: nvidia-cusolver-cu12 11.7.2.55[0m \u001b[32m24/36\u001b[0m [cuda-bindings]\n",
      "\u001b[2K    Uninstalling nvidia-cusolver-cu12-11.7.2.55:m━━━━━━━━━━━━━\u001b[0m \u001b[32m24/36\u001b[0m [cuda-bindings]\n",
      "\u001b[2K      Successfully uninstalled nvidia-cusolver-cu12-11.7.2.55━━━━━\u001b[0m \u001b[32m25/36\u001b[0m [nvidia-cusolver-cu12]\n",
      "\u001b[2K  Attempting uninstall: transformers\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m26/36\u001b[0m [diffusers]olver-cu12]\n",
      "\u001b[2K    Found existing installation: transformers 5.2.0━━━━━━━━━━━\u001b[0m \u001b[32m26/36\u001b[0m [diffusers]\n",
      "\u001b[2K    Uninstalling transformers-5.2.0:━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m27/36\u001b[0m [transformers]\n",
      "\u001b[2K      Successfully uninstalled transformers-5.2.0[90m━━━━━━━━━\u001b[0m \u001b[32m27/36\u001b[0m [transformers]\n",
      "\u001b[2K  Attempting uninstall: torch━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m27/36\u001b[0m [transformers]\n",
      "\u001b[2K    Found existing installation: torch 2.7.1+cu12890m━━━━━━━━━\u001b[0m \u001b[32m27/36\u001b[0m [transformers]\n",
      "\u001b[2K    Uninstalling torch-2.7.1+cu128:━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m28/36\u001b[0m [torch]rs]\n",
      "\u001b[2K      Successfully uninstalled torch-2.7.1+cu128╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m28/36\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: datasets━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m28/36\u001b[0m [torch]\n",
      "\u001b[2K    Found existing installation: datasets 4.5.00m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m28/36\u001b[0m [torch]\n",
      "\u001b[2K    Uninstalling datasets-4.5.0:━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m28/36\u001b[0m [torch]\n",
      "\u001b[2K      Successfully uninstalled datasets-4.5.0\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m28/36\u001b[0m [torch]\n",
      "\u001b[2K  Attempting uninstall: torchvision━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m30/36\u001b[0m [xformers]\n",
      "\u001b[2K    Found existing installation: torchvision 0.22.1+cu128━━━━━\u001b[0m \u001b[32m30/36\u001b[0m [xformers]\n",
      "\u001b[2K    Uninstalling torchvision-0.22.1+cu128:\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m31/36\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled torchvision-0.22.1+cu1280m━━━━━\u001b[0m \u001b[32m31/36\u001b[0m [torchvision]\n",
      "\u001b[2K  Attempting uninstall: trl━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m31/36\u001b[0m [torchvision]\n",
      "\u001b[2K    Found existing installation: trl 0.28.0[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m31/36\u001b[0m [torchvision]\n",
      "\u001b[2K    Uninstalling trl-0.28.0:━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m31/36\u001b[0m [torchvision]\n",
      "\u001b[2K      Successfully uninstalled trl-0.28.0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m31/36\u001b[0m [torchvision]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36/36\u001b[0m [unsloth]5/36\u001b[0m [unsloth]zoo]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "rhai-innovation-mini-trainer 0.6.0 requires transformers>=5.0.0, but you have transformers 4.57.6 which is incompatible.\n",
      "instructlab-training 0.14.1 requires transformers>=5.0.0, but you have transformers 4.57.6 which is incompatible.\n",
      "feast 0.58.0 requires dill~=0.3.0, but you have dill 0.4.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed cuda-bindings-12.9.4 cuda-pathfinder-1.3.4 cut_cross_entropy-25.1.1 datasets-4.3.0 diffusers-0.36.0 fsspec-2025.9.0 hf_transfer-0.1.9 huggingface_hub-0.36.2 msgspec-0.20.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.8.4.1 nvidia-cuda-cupti-cu12-12.8.90 nvidia-cuda-nvrtc-cu12-12.8.93 nvidia-cuda-runtime-cu12-12.8.90 nvidia-cudnn-cu12-9.10.2.21 nvidia-cufft-cu12-11.3.3.83 nvidia-cufile-cu12-1.13.1.3 nvidia-curand-cu12-10.3.9.90 nvidia-cusolver-cu12-11.7.3.90 nvidia-cusparse-cu12-12.5.8.93 nvidia-cusparselt-cu12-0.7.1 nvidia-nccl-cu12-2.27.5 nvidia-nvjitlink-cu12-12.8.93 nvidia-nvshmem-cu12-3.4.5 nvidia-nvtx-cu12-12.8.90 sentencepiece-0.2.1 torch-2.10.0 torchao-0.16.0 torchvision-0.25.0 transformers-4.57.6 triton-3.6.0 trl-0.24.0 tyro-1.0.6 unsloth-2026.2.1 unsloth_zoo-2026.2.1 xformers-0.0.34\n"
     ]
    }
   ],
   "source": [
    "! pip install unsloth \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "933acade-845a-40f2-b77f-4e22dd3eb4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.12/site-packages/training_hub/algorithms/lora.py:17: UserWarning: WARNING: Unsloth should be imported before [transformers] to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  from unsloth import FastLanguageModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed editing tqdm to replace Inductor Compilation:\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "Failed to import dependencies for Unsloth backend: cannot import name 'CompileCounterInt' from 'torch._dynamo.utils' (/opt/app-root/lib64/python3.12/site-packages/torch/_dynamo/utils.py)\nInstall LoRA dependencies with: pip install 'training-hub[lora]'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/training_hub/algorithms/lora.py:17\u001b[39m, in \u001b[36mUnslothLoRABackend.execute_training\u001b[39m\u001b[34m(self, algorithm_params)\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m FastLanguageModel\n\u001b[32m     18\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtrl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SFTTrainer, SFTConfig\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/unsloth/__init__.py:95\u001b[39m\n\u001b[32m     87\u001b[39m         \u001b[38;5;66;03m# if os.environ.get(\"UNSLOTH_DISABLE_AUTO_UPDATES\", \"0\") == \"0\":\u001b[39;00m\n\u001b[32m     88\u001b[39m         \u001b[38;5;66;03m#     try:\u001b[39;00m\n\u001b[32m     89\u001b[39m         \u001b[38;5;66;03m#         os.system(\"pip install --upgrade --no-cache-dir --no-deps unsloth_zoo\")\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     93\u001b[39m         \u001b[38;5;66;03m#         except:\u001b[39;00m\n\u001b[32m     94\u001b[39m         \u001b[38;5;66;03m#             raise ImportError(\"Unsloth: Please update unsloth_zoo via `pip install --upgrade --no-cache-dir --no-deps unsloth_zoo`\")\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m95\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01munsloth_zoo\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m PackageNotFoundError:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/unsloth_zoo/__init__.py:205\u001b[39m\n\u001b[32m    203\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mUNSLOTH_ZOO_IS_PRESENT\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtemporary_patches\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    206\u001b[39m     encode_conversations_with_harmony,\n\u001b[32m    207\u001b[39m )\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mrl_environments\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m    209\u001b[39m     check_python_modules,\n\u001b[32m    210\u001b[39m     create_locked_down_function,\n\u001b[32m   (...)\u001b[39m\u001b[32m    214\u001b[39m     launch_openenv,\n\u001b[32m    215\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/unsloth_zoo/temporary_patches/__init__.py:21\u001b[39m\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmisc\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgemma3n\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n\u001b[32m     22\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mgpt_oss\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m *\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/unsloth_zoo/temporary_patches/gemma3n.py:51\u001b[39m\n\u001b[32m     48\u001b[39m \u001b[38;5;66;03m# We only execute this for float16 so it's not always executed\u001b[39;00m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# TEMPORARY_PATCHES.append(patch_Gemma3nConvNormAct_forward)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m \u001b[38;5;129m@torch_compile\u001b[39m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mGemma3nRMSNorm_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch.Tensor) -> torch.Tensor:\n\u001b[32m     53\u001b[39m     \u001b[38;5;66;03m# Llama does x.to(float16) * w whilst Gemma2 is (x * w).to(float16)\u001b[39;00m\n\u001b[32m     54\u001b[39m     \u001b[38;5;66;03m# See https://github.com/huggingface/transformers/pull/29402\u001b[39;00m\n\u001b[32m     55\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._norm(x.float()) * \u001b[38;5;28mself\u001b[39m.weight.float()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/torch/__init__.py:2572\u001b[39m, in \u001b[36mcompile\u001b[39m\u001b[34m(model, fullgraph, dynamic, backend, mode, options, disable)\u001b[39m\n\u001b[32m   2546\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompile\u001b[39m(\n\u001b[32m   2547\u001b[39m     model: _Callable[_InputT, _RetT] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2548\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2557\u001b[39m     | _Callable[_InputT, _RetT]\n\u001b[32m   2558\u001b[39m ):\n\u001b[32m   2559\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   2560\u001b[39m \u001b[33;03m    Optimizes given model/function using TorchDynamo and specified backend.\u001b[39;00m\n\u001b[32m   2561\u001b[39m \u001b[33;03m    If you are compiling an :class:`torch.nn.Module`, you can also use :meth:`torch.nn.Module.compile`\u001b[39;00m\n\u001b[32m   2562\u001b[39m \u001b[33;03m    to compile the module inplace without changing its structure.\u001b[39;00m\n\u001b[32m   2563\u001b[39m \n\u001b[32m   2564\u001b[39m \u001b[33;03m    Concretely, for every frame executed within the compiled region, we will attempt\u001b[39;00m\n\u001b[32m   2565\u001b[39m \u001b[33;03m    to compile it and cache the compiled result on the code object for future\u001b[39;00m\n\u001b[32m   2566\u001b[39m \u001b[33;03m    use.  A single frame may be compiled multiple times if previous compiled\u001b[39;00m\n\u001b[32m   2567\u001b[39m \u001b[33;03m    results are not applicable for subsequent calls (this is called a \"guard\u001b[39;00m\n\u001b[32m   2568\u001b[39m \u001b[33;03m    failure\"), you can use TORCH_LOGS=guards to debug these situations.\u001b[39;00m\n\u001b[32m   2569\u001b[39m \u001b[33;03m    Multiple compiled results can be associated with a frame up to\u001b[39;00m\n\u001b[32m   2570\u001b[39m \u001b[33;03m    ``torch._dynamo.config.recompile_limit``, which defaults to 8; at which\u001b[39;00m\n\u001b[32m   2571\u001b[39m \u001b[33;03m    point we will fall back to eager.  Note that compile caches are per\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2572\u001b[39m \u001b[33;03m    *code object*, not frame; if you dynamically create multiple copies of a\u001b[39;00m\n\u001b[32m   2573\u001b[39m \u001b[33;03m    function, they will all share the same code cache.\u001b[39;00m\n\u001b[32m   2574\u001b[39m \n\u001b[32m   2575\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   2576\u001b[39m \u001b[33;03m       model (Callable or None): Module/function to optimize\u001b[39;00m\n\u001b[32m   2577\u001b[39m \u001b[33;03m       fullgraph (bool): If False (default), torch.compile attempts to discover compilable regions\u001b[39;00m\n\u001b[32m   2578\u001b[39m \u001b[33;03m        in the function that it will optimize. If True, then we require that the entire function be\u001b[39;00m\n\u001b[32m   2579\u001b[39m \u001b[33;03m        capturable into a single graph. If this is not possible (that is, if there are graph breaks),\u001b[39;00m\n\u001b[32m   2580\u001b[39m \u001b[33;03m        then this will raise an error. This also opts into unbacked semantics, notably it will turn on\u001b[39;00m\n\u001b[32m   2581\u001b[39m \u001b[33;03m        capture_scalar_outputs and capture_dynamic_output_shape_ops on by default.\u001b[39;00m\n\u001b[32m   2582\u001b[39m \u001b[33;03m       dynamic (bool or None): Use dynamic shape tracing.  When this is True, we will up-front attempt\u001b[39;00m\n\u001b[32m   2583\u001b[39m \u001b[33;03m        to generate a kernel that is as dynamic as possible to avoid recompilations when\u001b[39;00m\n\u001b[32m   2584\u001b[39m \u001b[33;03m        sizes change.  This may not always work as some operations/optimizations will\u001b[39;00m\n\u001b[32m   2585\u001b[39m \u001b[33;03m        force specialization; use TORCH_LOGS=dynamic to debug overspecialization.\u001b[39;00m\n\u001b[32m   2586\u001b[39m \u001b[33;03m        When this is False, we will NEVER generate dynamic kernels, we will always specialize.\u001b[39;00m\n\u001b[32m   2587\u001b[39m \u001b[33;03m        By default (None), we automatically detect if dynamism has occurred and compile a more\u001b[39;00m\n\u001b[32m   2588\u001b[39m \u001b[33;03m        dynamic kernel upon recompile.\u001b[39;00m\n\u001b[32m   2589\u001b[39m \u001b[33;03m       backend (str or Callable): backend to be used\u001b[39;00m\n\u001b[32m   2590\u001b[39m \n\u001b[32m   2591\u001b[39m \u001b[33;03m        - \"inductor\" is the default backend, which is a good balance between performance and overhead\u001b[39;00m\n\u001b[32m   2592\u001b[39m \n\u001b[32m   2593\u001b[39m \u001b[33;03m        - Non experimental in-tree backends can be seen with `torch._dynamo.list_backends()`\u001b[39;00m\n\u001b[32m   2594\u001b[39m \n\u001b[32m   2595\u001b[39m \u001b[33;03m        - Experimental or debug in-tree backends can be seen with `torch._dynamo.list_backends(None)`\u001b[39;00m\n\u001b[32m   2596\u001b[39m \n\u001b[32m   2597\u001b[39m \u001b[33;03m        - To register an out-of-tree custom backend:\u001b[39;00m\n\u001b[32m   2598\u001b[39m \u001b[33;03m          https://pytorch.org/docs/main/torch.compiler_custom_backends.html#registering-custom-backends\u001b[39;00m\n\u001b[32m   2599\u001b[39m \u001b[33;03m       mode (str): Can be either \"default\", \"reduce-overhead\", \"max-autotune\" or \"max-autotune-no-cudagraphs\"\u001b[39;00m\n\u001b[32m   2600\u001b[39m \n\u001b[32m   2601\u001b[39m \u001b[33;03m        - \"default\" is the default mode, which is a good balance between performance and overhead\u001b[39;00m\n\u001b[32m   2602\u001b[39m \n\u001b[32m   2603\u001b[39m \u001b[33;03m        - \"reduce-overhead\" is a mode that reduces the overhead of python with CUDA graphs,\u001b[39;00m\n\u001b[32m   2604\u001b[39m \u001b[33;03m          useful for small batches.  Reduction of overhead can come at the cost of more memory\u001b[39;00m\n\u001b[32m   2605\u001b[39m \u001b[33;03m          usage, as we will cache the workspace memory required for the invocation so that we\u001b[39;00m\n\u001b[32m   2606\u001b[39m \u001b[33;03m          do not have to reallocate it on subsequent runs.  Reduction of overhead is not guaranteed\u001b[39;00m\n\u001b[32m   2607\u001b[39m \u001b[33;03m          to work; today, we only reduce overhead for CUDA only graphs which do not mutate inputs.\u001b[39;00m\n\u001b[32m   2608\u001b[39m \u001b[33;03m          There are other circumstances where CUDA graphs are not applicable; use TORCH_LOG=perf_hints\u001b[39;00m\n\u001b[32m   2609\u001b[39m \u001b[33;03m          to debug.\u001b[39;00m\n\u001b[32m   2610\u001b[39m \n\u001b[32m   2611\u001b[39m \u001b[33;03m        - \"max-autotune\" is a mode that leverages Triton or template based matrix multiplications\u001b[39;00m\n\u001b[32m   2612\u001b[39m \u001b[33;03m          on supported devices and Triton based convolutions on GPU.\u001b[39;00m\n\u001b[32m   2613\u001b[39m \u001b[33;03m          It enables CUDA graphs by default on GPU.\u001b[39;00m\n\u001b[32m   2614\u001b[39m \n\u001b[32m   2615\u001b[39m \u001b[33;03m        - \"max-autotune-no-cudagraphs\" is a mode similar to \"max-autotune\" but without CUDA graphs\u001b[39;00m\n\u001b[32m   2616\u001b[39m \n\u001b[32m   2617\u001b[39m \u001b[33;03m        - To see the exact configs that each mode sets you can call `torch._inductor.list_mode_options()`\u001b[39;00m\n\u001b[32m   2618\u001b[39m \n\u001b[32m   2619\u001b[39m \u001b[33;03m       options (dict): A dictionary of options to pass to the backend. Some notable ones to try out are\u001b[39;00m\n\u001b[32m   2620\u001b[39m \n\u001b[32m   2621\u001b[39m \u001b[33;03m        - `epilogue_fusion` which fuses pointwise ops into templates. Requires `max_autotune` to also be set\u001b[39;00m\n\u001b[32m   2622\u001b[39m \n\u001b[32m   2623\u001b[39m \u001b[33;03m        - `max_autotune` which will profile to pick the best matmul configuration\u001b[39;00m\n\u001b[32m   2624\u001b[39m \n\u001b[32m   2625\u001b[39m \u001b[33;03m        - `fallback_random` which is useful when debugging accuracy issues\u001b[39;00m\n\u001b[32m   2626\u001b[39m \n\u001b[32m   2627\u001b[39m \u001b[33;03m        - `shape_padding` which pads matrix shapes to better align loads on GPUs especially for tensor cores\u001b[39;00m\n\u001b[32m   2628\u001b[39m \n\u001b[32m   2629\u001b[39m \u001b[33;03m        - `triton.cudagraphs` which will reduce the overhead of python with CUDA graphs\u001b[39;00m\n\u001b[32m   2630\u001b[39m \n\u001b[32m   2631\u001b[39m \u001b[33;03m        - `trace.enabled` which is the most useful debugging flag to turn on\u001b[39;00m\n\u001b[32m   2632\u001b[39m \n\u001b[32m   2633\u001b[39m \u001b[33;03m        - `trace.graph_diagram` which will show you a picture of your graph after fusion\u001b[39;00m\n\u001b[32m   2634\u001b[39m \n\u001b[32m   2635\u001b[39m \u001b[33;03m        - `guard_filter_fn` that controls which dynamo guards are saved with compilations.\u001b[39;00m\n\u001b[32m   2636\u001b[39m \u001b[33;03m          This is an unsafe feature and there is no backward compatibility guarantee provided\u001b[39;00m\n\u001b[32m   2637\u001b[39m \u001b[33;03m          for dynamo guards as data types.\u001b[39;00m\n\u001b[32m   2638\u001b[39m \u001b[33;03m          For stable helper functions to use, see the documentations in `torch.compiler`, for example:\u001b[39;00m\n\u001b[32m   2639\u001b[39m \u001b[33;03m          - `torch.compiler.skip_guard_on_inbuilt_nn_modules_unsafe`\u001b[39;00m\n\u001b[32m   2640\u001b[39m \u001b[33;03m          - `torch.compiler.skip_guard_on_all_nn_modules_unsafe`\u001b[39;00m\n\u001b[32m   2641\u001b[39m \u001b[33;03m          - `torch.compiler.keep_tensor_guards_unsafe`\u001b[39;00m\n\u001b[32m   2642\u001b[39m \n\u001b[32m   2643\u001b[39m \u001b[33;03m        - For inductor you can see the full list of configs that it supports by calling `torch._inductor.list_options()`\u001b[39;00m\n\u001b[32m   2644\u001b[39m \u001b[33;03m       disable (bool): Turn torch.compile() into a no-op for testing\u001b[39;00m\n\u001b[32m   2645\u001b[39m \n\u001b[32m   2646\u001b[39m \u001b[33;03m    Example::\u001b[39;00m\n\u001b[32m   2647\u001b[39m \n\u001b[32m   2648\u001b[39m \u001b[33;03m        @torch.compile(options={\"triton.cudagraphs\": True}, fullgraph=True)\u001b[39;00m\n\u001b[32m   2649\u001b[39m \u001b[33;03m        def foo(x):\u001b[39;00m\n\u001b[32m   2650\u001b[39m \u001b[33;03m            return torch.sin(x) + torch.cos(x)\u001b[39;00m\n\u001b[32m   2651\u001b[39m \n\u001b[32m   2652\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m   2653\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msysconfig\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/torch/_dynamo/eval_frame.py:944\u001b[39m, in \u001b[36moptimize\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    938\u001b[39m     _set_error_on_graph_break(self.error_on_graph_break)\n\u001b[32m    940\u001b[39m # Ensure that if an assertion occurs after graph pushes\n\u001b[32m    941\u001b[39m # something onto the DynamicLayerStack then we pop it off (the\n\u001b[32m    942\u001b[39m # constructed graph code isn't guarded with try/finally).\n\u001b[32m    943\u001b[39m #\n\u001b[32m--> \u001b[39m\u001b[32m944\u001b[39m # This used to be a context but putting a `with` here is a noticeable\n\u001b[32m    945\u001b[39m # perf regression (#126293)\n\u001b[32m    946\u001b[39m saved_dynamic_layer_stack_depth = (\n\u001b[32m    947\u001b[39m     torch._C._functorch.get_dynamic_layer_stack_depth()\n\u001b[32m    948\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/torch/_dynamo/eval_frame.py:998\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(rebuild_ctx, backend, nopython, guard_export_fn, guard_fail_fn, disable, dynamic)\u001b[39m\n\u001b[32m    995\u001b[39m compile_wrapper._torchdynamo_orig_callable = fn  # type: ignore[attr-defined]\n\u001b[32m    997\u001b[39m # when compiling user function instead of nn.Module\n\u001b[32m--> \u001b[39m\u001b[32m998\u001b[39m # provide public api _fn.get_compiler_config()\n\u001b[32m    999\u001b[39m assert not hasattr(compile_wrapper, \"get_compiler_config\")\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/torch/_dynamo/eval_frame.py:878\u001b[39m, in \u001b[36mget_compiler_fn\u001b[39m\u001b[34m(compiler_fn)\u001b[39m\n\u001b[32m    877\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m     filename = inspect.getsourcefile(fn)\n\u001b[32m    879\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/torch/_dynamo/repro/after_dynamo.py:33\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfx\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdebug_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     34\u001b[39m     AccuracyError,\n\u001b[32m     35\u001b[39m     backend_accuracy_fails,\n\u001b[32m     36\u001b[39m     BUCK_CMD_PREFIX,\n\u001b[32m     37\u001b[39m     BuckTargetWriter,\n\u001b[32m     38\u001b[39m     extra_imports,\n\u001b[32m     39\u001b[39m     generate_config_string,\n\u001b[32m     40\u001b[39m     generate_env_vars_string,\n\u001b[32m     41\u001b[39m     helper_for_dump_minify,\n\u001b[32m     42\u001b[39m     InputReader,\n\u001b[32m     43\u001b[39m     InputWriter,\n\u001b[32m     44\u001b[39m     minifier_dir,\n\u001b[32m     45\u001b[39m     NNModuleToString,\n\u001b[32m     46\u001b[39m     NopInputReader,\n\u001b[32m     47\u001b[39m     run_fwd_maybe_bwd,\n\u001b[32m     48\u001b[39m     same_two_models,\n\u001b[32m     49\u001b[39m )\n\u001b[32m     50\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfx\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexperimental\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01msymbolic_shapes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m fx_placeholder_targets\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/torch/_dynamo/debug_utils.py:43\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Tensor\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_dynamo\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtesting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m rand_strided\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01m_inductor\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcpp_builder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m normalize_path_separator\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/torch/_dynamo/testing.py:45\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtypes\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ConvertFrameReturn, DynamoFrameType, wrap_guarded_code\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CompileCounterInt, same\n\u001b[32m     48\u001b[39m np: Optional[types.ModuleType] = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'CompileCounterInt' from 'torch._dynamo.utils' (/opt/app-root/lib64/python3.12/site-packages/torch/_dynamo/utils.py)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtraining_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m lora_sft\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m result = \u001b[43mlora_sft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mibm-granite/granite-3.2-8b-instruct\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining_data.jsonl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mckpt_output_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./checkpoints\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mTraining complete.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(result)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/training_hub/algorithms/lora.py:817\u001b[39m, in \u001b[36mlora_sft\u001b[39m\u001b[34m(model_path, data_path, ckpt_output_dir, backend, lora_r, lora_alpha, lora_dropout, target_modules, num_epochs, effective_batch_size, micro_batch_size, gradient_accumulation_steps, learning_rate, max_seq_len, lr_scheduler, warmup_steps, load_in_4bit, load_in_8bit, bnb_4bit_quant_type, bnb_4bit_compute_dtype, bnb_4bit_use_double_quant, flash_attention, sample_packing, bf16, fp16, tf32, save_steps, eval_steps, logging_steps, save_total_limit, wandb_project, wandb_entity, wandb_run_name, dataset_type, field_messages, field_instruction, field_input, field_output, nproc_per_node, nnodes, node_rank, rdzv_id, rdzv_endpoint, master_addr, master_port, enable_model_splitting, **kwargs)\u001b[39m\n\u001b[32m    814\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_algorithm\n\u001b[32m    816\u001b[39m algorithm = create_algorithm(\u001b[33m'\u001b[39m\u001b[33mlora_sft\u001b[39m\u001b[33m'\u001b[39m, backend)\n\u001b[32m--> \u001b[39m\u001b[32m817\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    818\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    819\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    820\u001b[39m \u001b[43m    \u001b[49m\u001b[43mckpt_output_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    821\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlora_r\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlora_r\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    822\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlora_alpha\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlora_alpha\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    823\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlora_dropout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlora_dropout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    824\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_modules\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    826\u001b[39m \u001b[43m    \u001b[49m\u001b[43meffective_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43meffective_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    827\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmicro_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmicro_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    828\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgradient_accumulation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    829\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    830\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    831\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlr_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    832\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    833\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_in_4bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    834\u001b[39m \u001b[43m    \u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mload_in_8bit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    835\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbnb_4bit_quant_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbnb_4bit_quant_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    836\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbnb_4bit_compute_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbnb_4bit_compute_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    837\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbnb_4bit_use_double_quant\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbnb_4bit_use_double_quant\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    838\u001b[39m \u001b[43m    \u001b[49m\u001b[43mflash_attention\u001b[49m\u001b[43m=\u001b[49m\u001b[43mflash_attention\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    839\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_packing\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_packing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    840\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbf16\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbf16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    841\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfp16\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfp16\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtf32\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtf32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    844\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    845\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogging_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    846\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_total_limit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    847\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwandb_project\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwandb_project\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    848\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwandb_entity\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwandb_entity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    849\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwandb_run_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwandb_run_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    850\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdataset_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    851\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfield_messages\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    852\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfield_instruction\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_instruction\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    853\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfield_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    854\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfield_output\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfield_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    855\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnproc_per_node\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnproc_per_node\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    856\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    857\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnode_rank\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    858\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrdzv_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrdzv_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    859\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrdzv_endpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrdzv_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaster_addr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaster_addr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    861\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaster_port\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaster_port\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[43m    \u001b[49m\u001b[43menable_model_splitting\u001b[49m\u001b[43m=\u001b[49m\u001b[43menable_model_splitting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    863\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    864\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/training_hub/algorithms/lora.py:584\u001b[39m, in \u001b[36mLoRASFTAlgorithm.train\u001b[39m\u001b[34m(self, model_path, data_path, ckpt_output_dir, num_epochs, effective_batch_size, learning_rate, max_seq_len, max_tokens_per_gpu, data_output_dir, save_samples, warmup_steps, accelerate_full_state_at_epoch, checkpoint_at_epoch, lora_r, lora_alpha, lora_dropout, target_modules, use_rslora, use_dora, init_lora_weights, rank_pattern, alpha_pattern, loftq_config, load_in_4bit, load_in_8bit, bnb_4bit_quant_type, bnb_4bit_compute_dtype, bnb_4bit_use_double_quant, micro_batch_size, gradient_accumulation_steps, lr_scheduler, weight_decay, max_grad_norm, flash_attention, sample_packing, bf16, fp16, tf32, save_steps, eval_steps, logging_steps, save_total_limit, wandb_project, wandb_entity, wandb_run_name, dataset_type, field_messages, field_instruction, field_input, field_output, nproc_per_node, nnodes, node_rank, rdzv_id, rdzv_endpoint, master_addr, master_port, enable_model_splitting, **kwargs)\u001b[39m\n\u001b[32m    581\u001b[39m \u001b[38;5;66;03m# Apply PEFT configuration using the extender\u001b[39;00m\n\u001b[32m    582\u001b[39m params = \u001b[38;5;28mself\u001b[39m.peft_extender.apply_peft_config(params)\n\u001b[32m--> \u001b[39m\u001b[32m584\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/training_hub/algorithms/lora.py:34\u001b[39m, in \u001b[36mUnslothLoRABackend.execute_training\u001b[39m\u001b[34m(self, algorithm_params)\u001b[39m\n\u001b[32m     29\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     30\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTRL is required for Unsloth LoRA training. Install with:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     31\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mpip install \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtraining-hub[lora]\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     32\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[32m     35\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFailed to import dependencies for Unsloth backend: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     36\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mInstall LoRA dependencies with: pip install \u001b[39m\u001b[33m'\u001b[39m\u001b[33mtraining-hub[lora]\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     37\u001b[39m         ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Use all parameters as training parameters\u001b[39;00m\n\u001b[32m     40\u001b[39m \u001b[38;5;66;03m# Note: Torchrun parameters (nproc_per_node, etc.) are handled by the torchrun launcher,\u001b[39;00m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# not by the Python training code. The training code auto-detects distributed environment\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# via environment variables (WORLD_SIZE, LOCAL_RANK, etc.) set by torchrun.\u001b[39;00m\n\u001b[32m     43\u001b[39m training_params = algorithm_params\n",
      "\u001b[31mImportError\u001b[39m: Failed to import dependencies for Unsloth backend: cannot import name 'CompileCounterInt' from 'torch._dynamo.utils' (/opt/app-root/lib64/python3.12/site-packages/torch/_dynamo/utils.py)\nInstall LoRA dependencies with: pip install 'training-hub[lora]'"
     ]
    }
   ],
   "source": [
    "from training_hub import lora_sft\n",
    "\n",
    "result = lora_sft(\n",
    "    model_path=\"ibm-granite/granite-3.2-8b-instruct\",\n",
    "    data_path=\"training_data.jsonl\",\n",
    "    ckpt_output_dir=\"./checkpoints\",\n",
    "    num_epochs=3,\n",
    "    learning_rate=1e-5,\n",
    ")\n",
    "\n",
    "print(\"Training complete.\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1e6c1838-4f20-4f7e-97d6-2730a6e25cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Feb 19 05:00:30 2026       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA L40S                    On  |   00000000:30:00.0 Off |                    0 |\n",
      "| N/A   47C    P0            103W /  350W |    6663MiB /  46068MiB |      0%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "\n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A            1123      C   /opt/app-root/bin/python3              1818MiB |\n",
      "|    0   N/A  N/A            2759      C   /opt/app-root/bin/python3              1756MiB |\n",
      "|    0   N/A  N/A            3423      C   /opt/app-root/bin/python3               768MiB |\n",
      "|    0   N/A  N/A            4192      C   /opt/app-root/bin/python3              2296MiB |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c46f1754-77cd-4bfb-9051-0d790510597e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ERROR] `head_mask` is part of BloomModel.forward's signature, but not documented. Make sure to add it to the docstring of the function in /opt/app-root/lib64/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py.\n",
      "[ERROR] `head_mask` is part of BloomForCausalLM.forward's signature, but not documented. Make sure to add it to the docstring of the function in /opt/app-root/lib64/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py.\n",
      "[ERROR] `head_mask` is part of BloomForSequenceClassification.forward's signature, but not documented. Make sure to add it to the docstring of the function in /opt/app-root/lib64/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py.\n",
      "[ERROR] `head_mask` is part of BloomForTokenClassification.forward's signature, but not documented. Make sure to add it to the docstring of the function in /opt/app-root/lib64/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py.\n",
      "[ERROR] `head_mask` is part of BloomForQuestionAnswering.forward's signature, but not documented. Make sure to add it to the docstring of the function in /opt/app-root/lib64/python3.12/site-packages/transformers/models/bloom/modeling_bloom.py.\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'is_tf_available' from 'transformers.utils' (/opt/app-root/lib64/python3.12/site-packages/transformers/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtraining_hub\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m sft\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m result = \u001b[43msft\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mibm-granite/granite-3.2-8b-instruct\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining_data.jsonl\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mckpt_output_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./checkpoints\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_output_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m./data_output\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens_per_gpu\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m512\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43meffective_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/training_hub/algorithms/sft.py:307\u001b[39m, in \u001b[36msft\u001b[39m\u001b[34m(model_path, data_path, ckpt_output_dir, backend, num_epochs, effective_batch_size, learning_rate, max_seq_len, max_tokens_per_gpu, data_output_dir, save_samples, warmup_steps, accelerate_full_state_at_epoch, checkpoint_at_epoch, is_pretraining, block_size, document_column_name, beta1, beta2, eps, weight_decay, nproc_per_node, nnodes, node_rank, rdzv_id, rdzv_endpoint, master_addr, master_port, **kwargs)\u001b[39m\n\u001b[32m    304\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m create_algorithm\n\u001b[32m    306\u001b[39m algorithm = create_algorithm(\u001b[33m'\u001b[39m\u001b[33msft\u001b[39m\u001b[33m'\u001b[39m, backend)\n\u001b[32m--> \u001b[39m\u001b[32m307\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m    \u001b[49m\u001b[43mckpt_output_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mckpt_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[43m    \u001b[49m\u001b[43meffective_batch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43meffective_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    313\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    314\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_seq_len\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    315\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_tokens_per_gpu\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens_per_gpu\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    316\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata_output_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_output_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    317\u001b[39m \u001b[43m    \u001b[49m\u001b[43msave_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[43m    \u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwarmup_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    319\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccelerate_full_state_at_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccelerate_full_state_at_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    320\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_at_epoch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_at_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    321\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_pretraining\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_pretraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    322\u001b[39m \u001b[43m    \u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mblock_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdocument_column_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdocument_column_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    326\u001b[39m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m=\u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    328\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnproc_per_node\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnproc_per_node\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnnodes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnnodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnode_rank\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnode_rank\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrdzv_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrdzv_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrdzv_endpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrdzv_endpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaster_addr\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaster_addr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaster_port\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmaster_port\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/training_hub/algorithms/sft.py:187\u001b[39m, in \u001b[36mSFTAlgorithm.train\u001b[39m\u001b[34m(self, model_path, data_path, ckpt_output_dir, num_epochs, effective_batch_size, learning_rate, max_seq_len, max_tokens_per_gpu, data_output_dir, save_samples, warmup_steps, accelerate_full_state_at_epoch, checkpoint_at_epoch, is_pretraining, block_size, document_column_name, beta1, beta2, eps, weight_decay, nproc_per_node, nnodes, node_rank, rdzv_id, rdzv_endpoint, master_addr, master_port, **kwargs)\u001b[39m\n\u001b[32m    183\u001b[39m         params[key] = value\n\u001b[32m    185\u001b[39m params.update(kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecute_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/training_hub/algorithms/sft.py:67\u001b[39m, in \u001b[36mInstructLabTrainingSFTBackend.execute_training\u001b[39m\u001b[34m(self, algorithm_params)\u001b[39m\n\u001b[32m     64\u001b[39m torchrun_args = TorchrunArgs(**final_torchrun_params)\n\u001b[32m     66\u001b[39m \u001b[38;5;66;03m# Execute training\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m67\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtorch_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorchrun_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtraining_args\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/instructlab/training/__init__.py:39\u001b[39m, in \u001b[36mrun_training\u001b[39m\u001b[34m(torch_args, train_args)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Wrapper around the main training job that calls torchrun.\"\"\"\u001b[39;00m\n\u001b[32m     38\u001b[39m \u001b[38;5;66;03m# Local\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmain_ds\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m run_training\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m run_training(torch_args=torch_args, train_args=train_args)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/instructlab/training/main_ds.py:47\u001b[39m\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# First Party\u001b[39;00m\n\u001b[32m     46\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minstructlab\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m config\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minstructlab\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01maccelerator\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Accelerator\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minstructlab\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mbatch_loss_manager\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BatchLossManager\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01minstructlab\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtraining\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     50\u001b[39m     DistributedBackend,\n\u001b[32m     51\u001b[39m     ModelTypes,\n\u001b[32m   (...)\u001b[39m\u001b[32m     54\u001b[39m     TrainingArgs,\n\u001b[32m     55\u001b[39m )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/instructlab/training/accelerator.py:15\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdistributed\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfsdp\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mwrap\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m transformer_auto_wrap_policy\n\u001b[32m     14\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m get_scheduler\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# First Party\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/transformers/utils/import_utils.py:2044\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(self, name)\u001b[39m\n\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/transformers/utils/import_utils.py:2238\u001b[39m, in \u001b[36m_get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2236\u001b[39m             missing_backends.append(backend)\n\u001b[32m   2237\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (importlib.metadata.PackageNotFoundError, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m2238\u001b[39m         missing_backends.append(backend)\n\u001b[32m   2240\u001b[39m \u001b[38;5;28mself\u001b[39m._modules = \u001b[38;5;28mself\u001b[39m._modules.union(module_keys)\n\u001b[32m   2242\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m key, values \u001b[38;5;129;01min\u001b[39;00m module.items():\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/transformers/utils/import_utils.py:2236\u001b[39m, in \u001b[36m_get_module\u001b[39m\u001b[34m(self, module_name)\u001b[39m\n\u001b[32m   2234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   2235\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m():\n\u001b[32m-> \u001b[39m\u001b[32m2236\u001b[39m         missing_backends.append(backend)\n\u001b[32m   2237\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (importlib.metadata.PackageNotFoundError, \u001b[38;5;167;01mModuleNotFoundError\u001b[39;00m, \u001b[38;5;167;01mRuntimeError\u001b[39;00m):\n\u001b[32m   2238\u001b[39m     missing_backends.append(backend)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.12/importlib/__init__.py:90\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m     88\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     89\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/transformers/optimization.py:26\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01moptim\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlr_scheduler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LambdaLR, ReduceLROnPlateau\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer_pt_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LayerWiseDummyOptimizer, LayerWiseDummyScheduler\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mtrainer_utils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SchedulerType\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m logging\n\u001b[32m     30\u001b[39m logger = logging.get_logger(\u001b[34m__name__\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/opt/app-root/lib64/python3.12/site-packages/transformers/trainer_utils.py:31\u001b[39m\n\u001b[32m     27\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtyping\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Any, Callable, NamedTuple, Optional, Union\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m31\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     32\u001b[39m     ExplicitEnum,\n\u001b[32m     33\u001b[39m     is_psutil_available,\n\u001b[32m     34\u001b[39m     is_tf_available,\n\u001b[32m     35\u001b[39m     is_torch_available,\n\u001b[32m     36\u001b[39m     is_torch_cuda_available,\n\u001b[32m     37\u001b[39m     is_torch_hpu_available,\n\u001b[32m     38\u001b[39m     is_torch_mlu_available,\n\u001b[32m     39\u001b[39m     is_torch_mps_available,\n\u001b[32m     40\u001b[39m     is_torch_musa_available,\n\u001b[32m     41\u001b[39m     is_torch_npu_available,\n\u001b[32m     42\u001b[39m     is_torch_xla_available,\n\u001b[32m     43\u001b[39m     is_torch_xpu_available,\n\u001b[32m     44\u001b[39m     requires_backends,\n\u001b[32m     45\u001b[39m )\n\u001b[32m     48\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_torch_available():\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'is_tf_available' from 'transformers.utils' (/opt/app-root/lib64/python3.12/site-packages/transformers/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "from training_hub import sft\n",
    "\n",
    "result = sft(\n",
    "    model_path=\"ibm-granite/granite-3.2-8b-instruct\",\n",
    "    data_path=\"training_data.jsonl\",\n",
    "    ckpt_output_dir=\"./checkpoints\",\n",
    "    data_output_dir=\"./data_output\",\n",
    "    num_epochs=3,\n",
    "    learning_rate=1e-5,\n",
    "    max_seq_len=512,\n",
    "    max_tokens_per_gpu=512,\n",
    "    effective_batch_size=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d06e210e-bcba-4177-a590-0616a03f6153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.2.0\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9436975-acbd-4c32-b030-64fa3a8ea950",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
